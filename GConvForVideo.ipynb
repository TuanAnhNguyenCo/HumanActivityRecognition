{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/anaconda3/envs/anhnct/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from util.img2bone import HandDetector\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from util.preprocessing import readVideoAndCovertToBone\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from loader.dataloader import SkeletonData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames,bones = readVideoAndCovertToBone(\"data/108_new/Video/A_0_02072023_07.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_adjacency_matrix():\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands()\n",
    "    adj = torch.zeros((21,21))\n",
    "    for connection in mp_hands.HAND_CONNECTIONS:\n",
    "        adj[connection[0],connection[1]] = 1\n",
    "        adj[connection[1],connection[0]] = 1\n",
    "    return adj "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "\tdef __init__(self, input_dim, output_dim, num_vetex, act=F.relu, dropout=0.5, bias=True):\n",
    "\t\tsuper(GraphConvolution, self).__init__()\n",
    "\n",
    "\t\tself.alpha = 1.\n",
    "\n",
    "\t\tself.act = act\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\tself.weight = nn.Parameter(torch.randn(input_dim, output_dim)).to(device)\n",
    "\t\tif bias:\n",
    "\t\t\tself.bias = nn.Parameter(torch.randn(output_dim)).to(device)\n",
    "\t\telse:\n",
    "\t\t\tself.bias = None\n",
    "\n",
    "\t\tfor w in [self.weight]:\n",
    "\t\t\tnn.init.xavier_normal_(w)\n",
    "\n",
    "\tdef normalize(self, m):\n",
    "\t\trowsum = torch.sum(m, 0)\n",
    "\t\tr_inv = torch.pow(rowsum, -0.5)\n",
    "\t\tr_mat_inv = torch.diag(r_inv).float()\n",
    "\n",
    "\t\tm_norm = torch.mm(r_mat_inv, m)\n",
    "\t\tm_norm = torch.mm(m_norm, r_mat_inv)\n",
    "\n",
    "\t\treturn m_norm\n",
    "\n",
    "\tdef forward(self, adj, x):\n",
    "\n",
    "\t\tx = self.dropout(x)\n",
    "\n",
    "\t\t# K-ordered Chebyshev polynomial\n",
    "\t\tadj_norm = self.normalize(adj)\n",
    "\t\tsqr_norm = self.normalize(torch.mm(adj,adj))\n",
    "\t\tm_norm = (self.alpha*adj_norm + (1.-self.alpha)*sqr_norm).to(device)\n",
    "\n",
    "\t\tx_tmp = torch.einsum('abcd,de->abce', x, self.weight)\n",
    "\t\tx_out = torch.einsum('ij,abid->abjd', m_norm, x_tmp)\n",
    "\t\tif self.bias is not None:\n",
    "\t\t\tx_out += self.bias\n",
    "\t\tx_out = self.act(x_out)\n",
    "  \n",
    "\t\t\n",
    "\t\treturn x_out\n",
    "\t\t\n",
    "\t\t\n",
    "\n",
    "class StandConvolution(nn.Module):\n",
    "\tdef __init__(self, dims, num_classes, dropout):\n",
    "\t\tsuper(StandConvolution, self).__init__()\n",
    "\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\tself.conv = nn.Sequential(\n",
    "\t\t\t\t\t\t\t\t   nn.Conv2d(dims[0], dims[1], kernel_size=5, stride=2),\n",
    "\t\t\t\t\t\t\t\t   nn.InstanceNorm2d(dims[1]),\n",
    "\t\t\t\t\t\t\t\t   nn.ReLU(inplace=True),\n",
    "\t\t\t\t\t\t\t\t   #nn.AvgPool2d(3, stride=2),\n",
    "\t\t\t\t\t\t\t\t   nn.Conv2d(dims[1], dims[2], kernel_size=5, stride=2),\n",
    "\t\t\t\t\t\t\t\t   nn.InstanceNorm2d(dims[2]),\n",
    "\t\t\t\t\t\t\t\t   nn.ReLU(inplace=True),\n",
    "\t\t\t\t\t\t\t\t   #nn.AvgPool2d(3, stride=2),\n",
    "\t\t\t\t\t\t\t\t   nn.Conv2d(dims[2], dims[3], kernel_size=5, stride=2),\n",
    "\t\t\t\t\t\t\t\t   nn.InstanceNorm2d(dims[3]),\n",
    "\t\t\t\t\t\t\t\t   nn.ReLU(inplace=True),\n",
    "\t\t\t\t\t\t\t\t   #nn.AvgPool2d(3, stride=2)\n",
    "\t\t\t\t\t\t\t\t   ).to(device)\n",
    "\n",
    "\t\tself.fc = nn.Linear(dims[3]*5*5, num_classes).to(device)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.dropout(x.permute(0,3,1,2))# (1,9,62,63)\n",
    "\t\tx_tmp = self.conv(x)\n",
    "\t\tprint(x_tmp.shape)\n",
    "\t\tx_out = self.fc(x_tmp.view(x.size(0), -1))\n",
    "\n",
    "\t\treturn x_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GGCN(nn.Module):\n",
    "\tdef __init__(self, adj, num_classes, gc_dims, sc_dims, dropout=0.5):\n",
    "\t\tsuper(GGCN, self).__init__()\n",
    "\n",
    "\t\t\n",
    "\t\tadj = adj + torch.eye(adj.size(0)).to(adj).detach()\n",
    "\t\tident = torch.eye(adj.size(0)).to(adj)\n",
    "\t\tzeros = torch.zeros(adj.size(0), adj.size(1)).to(adj)\n",
    "\t\tself.adj = torch.cat([torch.cat([adj, ident, zeros], 1),\n",
    "\t\t\t\t\t\t\t  torch.cat([ident, adj, ident], 1),\n",
    "\t\t\t\t\t\t\t  torch.cat([zeros, ident, adj], 1)], 0).float()\n",
    "\t\n",
    "\t\tself.gcl = GraphConvolution(gc_dims[0], gc_dims[1], 21, dropout=dropout)\n",
    "\t\tself.conv= StandConvolution(sc_dims, num_classes, dropout=dropout)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# x: \n",
    "  \n",
    "\t\tmulti_conv = self.gcl(self.adj, x) \n",
    "\t\tlogit = self.conv(multi_conv) # (1,62,63,9)\n",
    "\t\treturn logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 5, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3183, -0.3478,  0.3921, -0.5736,  0.4513, -0.3731, -0.1355, -0.2202,\n",
       "         -0.2320, -0.7697, -0.0763,  0.1613, -0.7851, -0.1988,  0.2106, -0.0786,\n",
       "         -0.4804, -0.5965,  0.2110],\n",
       "        [-0.3183, -0.3478,  0.3921, -0.5736,  0.4513, -0.3731, -0.1355, -0.2202,\n",
       "         -0.2320, -0.7697, -0.0763,  0.1613, -0.7851, -0.1988,  0.2106, -0.0786,\n",
       "         -0.4804, -0.5965,  0.2110]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor(bones)[:,2:].reshape(64,-1,3).unsqueeze(dim=0)\n",
    "b = torch.cat([b[:,:-2],b[:,1:-1],b[:,2:]],2).to(device)\n",
    "model = GGCN(find_adjacency_matrix(),19,[3,9],[9, 16, 32, 64],0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anhnct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
