{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/anaconda3/envs/anhnct/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from util.img2bone import HandDetector\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from loader.dataloader import MultiModalData1\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from util.log import Log\n",
    "from trainer import train,validate,get_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14228\n",
      "1375\n",
      "2419\n"
     ]
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(20)\n",
    "\n",
    "\n",
    "\n",
    "train_set = MultiModalData1(glob.glob(\"data/new_data/Scalogram/train2/*\"))\n",
    "test_set = MultiModalData1(glob.glob(\"data/new_data/Scalogram/test2/*\"))\n",
    "val_set = MultiModalData1(glob.glob(\"data/new_data/Scalogram/val2/*\"))\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64,\n",
    "                          drop_last=True, num_workers=3,shuffle=True)\n",
    "valid_loader = DataLoader(val_set, batch_size=64,\n",
    "                          drop_last=True, num_workers=3)\n",
    "test_loader = DataLoader(test_set, batch_size=64,\n",
    "                         drop_last=True, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSD 2-Clause License\n",
    "\n",
    "# Copyright (c) 2019 wangvation. All rights reserved.\n",
    "\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "\n",
    "# 1. Redistributions of source code must retain the above copyright notice,\n",
    "# this list of conditions and the following disclaimer.\n",
    "\n",
    "# 2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "#    this list of conditions and the following disclaimer in the documentation\n",
    "#    and/or other materials provided with the distribution.\n",
    "\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
    "# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY,\n",
    "# OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "# POSSIBILITY OF SUCH DAMAGE.\n",
    "# ============================================================================\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import AvgPool2d\n",
    "from torch.nn import Softmax2d\n",
    "from torch.nn import ReLU6\n",
    "from torch.nn.functional import relu6\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "  \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "  \"\"\"\n",
    "  if min_value is None:\n",
    "    min_value = divisor\n",
    "  new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "  # Make sure that round down does not go down by more than 10%.\n",
    "  if new_v < 0.9 * v:\n",
    "    new_v += divisor\n",
    "  return new_v\n",
    "\n",
    "\n",
    "class DepthSepConv(nn.Module):\n",
    "  \"\"\"docstring for Depthwise Separable Convolution\"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               in_channels,\n",
    "               out_channels,\n",
    "               ksize=3,\n",
    "               stride=1,\n",
    "               padding=1,\n",
    "               multiplier=1):\n",
    "    super(DepthSepConv, self).__init__()\n",
    "    in_channels = _make_divisible(in_channels * multiplier, 8)\n",
    "    out_channels = _make_divisible(out_channels * multiplier, 8)\n",
    "    self.depthwise_conv = Conv2d(in_channels=in_channels,\n",
    "                                 out_channels=in_channels,\n",
    "                                 kernel_size=ksize,\n",
    "                                 stride=stride,\n",
    "                                 padding=padding,\n",
    "                                 groups=in_channels)\n",
    "\n",
    "    self.bn1 = BatchNorm2d(in_channels)\n",
    "\n",
    "    self.pointwise_conv = Conv2d(in_channels=in_channels,\n",
    "                                 out_channels=out_channels,\n",
    "                                 kernel_size=1,\n",
    "                                 stride=1,\n",
    "                                 groups=1)\n",
    "    self.bn2 = BatchNorm2d(out_channels)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.depthwise_conv(x)\n",
    "    x = self.bn1(x)\n",
    "    x = relu(x)\n",
    "    x = self.pointwise_conv(x)\n",
    "    x = self.bn2(x)\n",
    "    x = relu(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class MobileNetV1(nn.Module):\n",
    "  \"\"\"\n",
    "  docstring for MobileNetV1\n",
    "  MobileNetV1 Body Architecture\n",
    "  | Type / Stride | Filter Shape        | Input Size     | Output Size      |\n",
    "  | :------------ | :------------------ | :------------- | :-------------   |\n",
    "  | Conv / s2     | 3 × 3 × 3 × 32      | 224 x 224 x 3  | 112 x 112 x 32   |\n",
    "  | Conv dw / s1  | 3 × 3 × 32 dw       | 112 x 112 x 32 | 112 x 112 x 32   |\n",
    "  | Conv / s1     | 1 × 1 × 32 x 64     | 112 x 112 x 32 | 112 x 112 x 64   |\n",
    "  | Conv dw / s2  | 3 × 3 × 64 dw       | 112 x 112 x 64 | 56 x 56 x 64     |\n",
    "  | Conv / s1     | 1 × 1 × 64 × 128    | 56 x 56 x 64   | 56 x 56 x 128    |\n",
    "  | Conv dw / s1  | 3 × 3 × 128 dw      | 56 x 56 x 128  | 56 x 56 x 128    |\n",
    "  | Conv / s1     | 1 × 1 × 128 × 128   | 56 x 56 x 128  | 56 x 56 x 128    |\n",
    "  | Conv dw / s2  | 3 × 3 × 128 dw      | 56 x 56 x 128  | 28 x 28 x 128    |\n",
    "  | Conv / s1     | 1 × 1 × 128 × 256   | 28 x 28 x 128  | 28 x 28 x 256    |\n",
    "  | Conv dw / s1  | 3 × 3 × 256 dw      | 28 x 28 x 256  | 28 x 28 x 256    |\n",
    "  | Conv / s1     | 1 × 1 × 256 × 256   | 28 x 28 x 256  | 28 x 28 x 256    |\n",
    "  | Conv dw / s2  | 3 × 3 × 256 dw      | 28 x 28 x 256  | 14 x 14 x 256    |\n",
    "  | Conv / s1     | 1 × 1 × 256 × 512   | 14 x 14 x 256  | 14 x 14 x 512    |\n",
    "  | Conv dw / s1  | 3 × 3 × 512 dw      | 14 x 14 x 512  | 14 x 14 x 512    |\n",
    "  | Conv / s1     | 1 × 1 × 512 × 512   | 14 x 14 x 512  | 14 x 14 x 512    |\n",
    "  | Conv dw / s1  | 3 × 3 × 512 dw      | 14 x 14 x 512  | 14 x 14 x 512    |\n",
    "  | Conv / s1     | 1 × 1 × 512 × 512   | 14 x 14 x 512  | 14 x 14 x 512    |\n",
    "  | Conv dw / s1  | 3 × 3 × 512 dw      | 14 x 14 x 512  | 14 x 14 x 512    |\n",
    "  | Conv / s1     | 1 × 1 × 512 × 512   | 14 x 14 x 512  | 14 x 14 x 512    |\n",
    "  | Conv dw / s1  | 3 × 3 × 512 dw      | 14 x 14 x 512  | 14 x 14 x 512    |\n",
    "  | Conv / s1     | 1 × 1 × 512 × 512   | 14 x 14 x 512  | 14 x 14 x 512    |\n",
    "  | Conv dw / s1  | 3 × 3 × 512 dw      | 14 x 14 x 512  | 14 x 14 x 512    |\n",
    "  | Conv / s1     | 1 × 1 × 512 × 512   | 14 x 14 x 512  | 14 x 14 x 512    |\n",
    "  | Conv dw / s2  | 3 × 3 × 512 dw      | 14 x 14 x 512  | 7 x 7 x 512      |\n",
    "  | Conv / s1     | 1 × 1 × 512 × 1024  | 7 x 7 x 512    | 7 x 7 x 1024     |\n",
    "  | Conv dw / s1  | 3 × 3 × 1024 dw     | 7 x 7 x 1024   | 7 x 7 x 1024     |\n",
    "  | Conv / s1     | 1 × 1 × 1024 × 1024 | 7 x 7 x 1024   | 7 x 7 x 1024     |\n",
    "  | AvgPool / s1  | Pool 7 × 7          | 7 x 7 x 1024   | 1 x 1 x 1024     |\n",
    "  | FC / s1       | 1024 x 1000         | 1 x 1 x 1024   | 1 x 1 x 1000     |\n",
    "  | Softmax / s1  | Classifier          | 1 x 1 x 1000   | 1 x 1 x 1000     |\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, resolution=224, num_classes=41, multiplier=1):\n",
    "\n",
    "    super(MobileNetV1, self).__init__()\n",
    "    self.name = \"MobileNetV1_%d_%03d\" % (resolution, int(multiplier * 100))\n",
    "    assert(resolution % 32 == 0)\n",
    "    self.first_in_channel = _make_divisible(32 * multiplier, 8)\n",
    "    self.last_out_channel = _make_divisible(1024 * multiplier, 8)\n",
    "    self.features = nn.Sequential(\n",
    "        Conv2d(8, self.first_in_channel, kernel_size=3, stride=2, padding=1),\n",
    "        DepthSepConv(32, 64, stride=1, multiplier=multiplier),\n",
    "        DepthSepConv(64, 128, stride=2, multiplier=multiplier),\n",
    "        DepthSepConv(128, 128, stride=1, multiplier=multiplier),\n",
    "        DepthSepConv(128, 256, stride=2, multiplier=multiplier),\n",
    "        DepthSepConv(256, 256, stride=1, multiplier=multiplier),\n",
    "        DepthSepConv(256, 512, stride=2, multiplier=multiplier),\n",
    "        DepthSepConv(512, 512, stride=1, multiplier=multiplier),\n",
    "        DepthSepConv(512, 512, stride=1, multiplier=multiplier),\n",
    "        DepthSepConv(512, 512, stride=1, multiplier=multiplier),\n",
    "        DepthSepConv(512, 512, stride=1, multiplier=multiplier),\n",
    "        DepthSepConv(512, 512, stride=1, multiplier=multiplier),\n",
    "        DepthSepConv(512, 1024, stride=2, multiplier=multiplier),\n",
    "        DepthSepConv(1024, 1024, stride=1, multiplier=multiplier))\n",
    "\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(50176,num_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    x = self.features(x)\n",
    "    x = self.classifier(x)\n",
    "   \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [03:46<00:00,  1.02s/it]\n",
      "100%|██████████| 37/37 [00:16<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 --- Train loss = 4.759764627461749 --- Valid loss = 4.17502500700142 -- Train set accuracy = 5.42652027027027 % Valid set Accuracy = 5.0675675675675675 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [03:29<00:00,  1.06it/s]\n",
      "100%|██████████| 37/37 [00:12<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 --- Train loss = 3.164108678527759 --- Valid loss = 4.43004446457542 -- Train set accuracy = 5.13795045045045 % Valid set Accuracy = 5.827702702702703 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [03:24<00:00,  1.08it/s]\n",
      "100%|██████████| 37/37 [00:13<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 --- Train loss = 2.8240911274176366 --- Valid loss = 5.383923226475265 -- Train set accuracy = 16.547015765765767 % Valid set Accuracy = 8.488175675675675 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [03:25<00:00,  1.08it/s]\n",
      "100%|██████████| 37/37 [00:12<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 --- Train loss = 2.543158015907429 --- Valid loss = 5.06550333267175 -- Train set accuracy = 6.932713963963964 % Valid set Accuracy = 5.489864864864865 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [03:24<00:00,  1.09it/s]\n",
      "100%|██████████| 37/37 [00:12<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 --- Train loss = 2.2845063026398535 --- Valid loss = 5.118074227606404 -- Train set accuracy = 4.898648648648648 % Valid set Accuracy = 3.125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [03:25<00:00,  1.08it/s]\n",
      "100%|██████████| 37/37 [00:12<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 --- Train loss = 2.050760888732552 --- Valid loss = 5.623036384116401 -- Train set accuracy = 6.883445945945946 % Valid set Accuracy = 4.096283783783784 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [03:28<00:00,  1.07it/s]\n",
      "100%|██████████| 37/37 [00:13<00:00,  2.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/disk1/anhnct/HAR/HumanActivityRecognition/test.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiotlabws/mnt/disk1/anhnct/HAR/HumanActivityRecognition/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiotlabws/mnt/disk1/anhnct/HAR/HumanActivityRecognition/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     model, valid_loss \u001b[39m=\u001b[39m validate(valid_loader, model, criterion, device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Baiotlabws/mnt/disk1/anhnct/HAR/HumanActivityRecognition/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m train_acc, f1_score_weighted, f1_score_micro \u001b[39m=\u001b[39m get_accuracy(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiotlabws/mnt/disk1/anhnct/HAR/HumanActivityRecognition/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     model, train_loader, device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiotlabws/mnt/disk1/anhnct/HAR/HumanActivityRecognition/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# save f1 score\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baiotlabws/mnt/disk1/anhnct/HAR/HumanActivityRecognition/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m train_f1score_weighted\u001b[39m.\u001b[39mappend(f1_score_weighted)\n",
      "File \u001b[0;32m/mnt/disk1/anhnct/HAR/HumanActivityRecognition/trainer.py:222\u001b[0m, in \u001b[0;36mget_accuracy\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m    220\u001b[0m predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(torch\u001b[39m.\u001b[39msoftmax(outputs, \u001b[39m1\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[1;32m    221\u001b[0m total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 222\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39;49m labels)\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m    223\u001b[0m predicted_labels\u001b[39m.\u001b[39mextend(predicted)\n\u001b[1;32m    224\u001b[0m truth_labels\u001b[39m.\u001b[39mextend(labels)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log = Log(\"log/VIT_Spec\", \"vit_emg\")\n",
    "model = MobileNetV1().to(device).double()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "epochs = 500\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "\n",
    "train_f1score_weighted = []\n",
    "val_f1scroe_weighted = []\n",
    "\n",
    "train_f1score_micro = []\n",
    "val_f1scroe_micro = []\n",
    "\n",
    "test_log = []\n",
    "\n",
    "best_f1 = -1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # training\n",
    "    model, train_loss, optimizer = train(\n",
    "        train_loader, model, criterion, optimizer, device)\n",
    "\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        model, valid_loss = validate(valid_loader, model, criterion, device)\n",
    "    train_acc, f1_score_weighted, f1_score_micro = get_accuracy(\n",
    "        model, train_loader, device)\n",
    "    # save f1 score\n",
    "    train_f1score_weighted.append(f1_score_weighted)\n",
    "    train_f1score_micro.append(f1_score_micro)\n",
    "\n",
    "    val_acc, f1_score_weighted, f1_score_micro = get_accuracy(\n",
    "        model, valid_loader, device)\n",
    "    # save f1 score\n",
    "    if best_f1 < f1_score_micro:\n",
    "        torch.save(model.state_dict(),\n",
    "                   f\"log/VIT_Spec/best_model{epoch}.pth\")\n",
    "        log.save_model(model)\n",
    "        best_f1 = f1_score_micro\n",
    "    val_f1scroe_weighted.append(f1_score_weighted)\n",
    "    val_f1scroe_micro.append(f1_score_micro)\n",
    "    print(\"Epoch {} --- Train loss = {} --- Valid loss = {} -- Train set accuracy = {} % Valid set Accuracy = {} %\".format\n",
    "          (epoch+1, train_loss, valid_loss, train_acc, val_acc))\n",
    "    # save loss value\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    # save accuracy\n",
    "    train_accuracy.append(train_acc)\n",
    "    val_accuracy.append(val_acc)\n",
    "\n",
    "    test_log.append(get_accuracy(model, test_loader, device))\n",
    "\n",
    "    log.save_training_log(train_losses, train_accuracy,\n",
    "                          train_f1score_weighted, train_f1score_micro)\n",
    "    log.save_val_log(valid_losses, val_accuracy,\n",
    "                     val_f1scroe_weighted, val_f1scroe_micro)\n",
    "    log.save_test_log(test_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anhnct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
