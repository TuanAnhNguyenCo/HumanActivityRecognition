{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/aiotlabws/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/disk1/anhnct/HAR/HumanActivityRecognition/wandb/run-20231031_135915-63mex7a6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/coanh2710/Missing_modality/runs/63mex7a6' target=\"_blank\">magical-pitchfork-303</a></strong> to <a href='https://wandb.ai/coanh2710/Missing_modality' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/coanh2710/Missing_modality' target=\"_blank\">https://wandb.ai/coanh2710/Missing_modality</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/coanh2710/Missing_modality/runs/63mex7a6' target=\"_blank\">https://wandb.ai/coanh2710/Missing_modality/runs/63mex7a6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47353\n",
      "13801\n",
      "14188\n",
      "0.8973987392217955 0.8964846746602742 0.9042700120883858 0.8964676041890346\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">magical-pitchfork-303</strong> at: <a href='https://wandb.ai/coanh2710/Missing_modality/runs/63mex7a6' target=\"_blank\">https://wandb.ai/coanh2710/Missing_modality/runs/63mex7a6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231031_135915-63mex7a6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trainer import ViT\n",
    "from VITforEMGAndBone import ViTForEMGAndBone, CrossAttention\n",
    "from GCNforVIdeo import GGCN, find_adjacency_matrix\n",
    "from torch import nn\n",
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "import math\n",
    "from loader.dataloader import MultiModalData\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from util.log import Log\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "wandb.login(\n",
    "    key='9bce1a84793dd8652665e9c5a731d2f7775245ad',\n",
    "    relogin=True\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"Missing_modality\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"epochs\": 100,\n",
    "        'random_seed': 20,\n",
    "        \"common_dim\": 64,\n",
    "        \"n_classes\": 41,\n",
    "        \"batch_size\": 128,\n",
    "        \"T\": 1,\n",
    "        \"device\":'cuda:1',\n",
    "        \"cl_rate\": 1,\n",
    "        \"param_vid\": 1.5,\n",
    "        \"param_emg\": 0.8\n",
    "    })\n",
    "\n",
    "\n",
    "class MultiModal(nn.Module):\n",
    "    def __init__(self, common_dim, n_classes):\n",
    "        super(MultiModal, self).__init__()\n",
    "        self.gcn = GGCN(find_adjacency_matrix(), 41,\n",
    "                        [3, 9], [9, 16, 32, 64], run.config[\"device\"], 0.0)\n",
    "        self.vit = ViT(emg_size=(44100*0.2, 8), patch_height=60, num_classes=41, dim=128,\n",
    "                       depth=5, mlp_dim=256, heads=8, pool='cls', dropout=0.45, emb_dropout=0.45).double()\n",
    "        self.crossAtt1 = CrossAttention(63, 14112, 512).double()\n",
    "        self.crossAtt2 = CrossAttention(14112, 63, 512).double()\n",
    "        self.vitForEMGandBone = ViTForEMGAndBone(\n",
    "            1024,  41, 512, 3, 8, 512, pool='cls', dim_head=64, dropout=0, emb_dropout=0).double()\n",
    "\n",
    "        self.fc = nn.Linear(common_dim, n_classes).double()\n",
    "        # self.act = nn.RELU() \n",
    "        self.act = nn.ReLU() \n",
    "        \n",
    "        self.fc1 = nn.Linear(1536, common_dim).double()\n",
    "        self.fc2 = nn.Linear(128, common_dim).double()\n",
    "        self.fc3 = nn.Linear(2176, common_dim).double()\n",
    "        self.fc4 = nn.Linear(common_dim, common_dim).double()\n",
    "        \n",
    "        self.classify = nn.Sequential(\n",
    "            nn.Linear(common_dim,common_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.1)\n",
    "        ).double()\n",
    "        self.drop = nn.Dropout(0.0)\n",
    "         \n",
    "    def forward(self, bones, emg):\n",
    "        x1 = self.gcn(bones)  # out\n",
    "        x1 = self.drop(x1)\n",
    "        x2 = self.vit(emg.double())  # out\n",
    "        emg1 = rearrange(emg, \"b (a d) c ->b a (d c) \", a=5).double()\n",
    "        bone1 = rearrange(bones, \"b t n c -> b t (n c)\").double()\n",
    "        x3 = self.crossAtt1(bone1, emg1)\n",
    "        x4 = self.crossAtt2(emg1, bone1)\n",
    "        x5 = self.vitForEMGandBone(torch.concat(\n",
    "            [x3, x4], dim=-1).double())  # out\n",
    "        x5 = torch.concat([x1, x2, x5], dim=-1)\n",
    "        # common dim\n",
    "        x1 = self.fc1(x1.double())\n",
    "        x2 = self.fc2(x2)\n",
    "        x5 = self.fc3(x5)\n",
    "        \n",
    "        x1 = self.fc4(x1)\n",
    "        x2 = self.fc4(x2)\n",
    "        x5 = self.fc4(x5)\n",
    "        \n",
    "        # classify\n",
    "        a1 = self.classify(x1) + x1\n",
    "        a2 = self.classify(x2) + x2\n",
    "        a5 = self.classify(x5) + x5\n",
    "\n",
    "        a1 = self.fc(a1)\n",
    "        a2 = self.fc(a2)\n",
    "        a5 = self.fc(a5)\n",
    "\n",
    "        return [x1, x2, x5], [a1, a2, a5]  # video,emg,multimodal\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "def super_gmc_loss(criterion,prediction, target, batch_representations, temperature, batch_size, cl_rate=2):\n",
    "    joint_mod_loss_sum = 0\n",
    "    for mod in range(len(batch_representations) - 1):\n",
    "        # Negative pairs: everything that is not in the current joint-modality pair\n",
    "        out_joint_mod = torch.cat(\n",
    "            [batch_representations[-1], batch_representations[mod]], dim=0\n",
    "        )\n",
    "        # [2*B, 2*B]\n",
    "        sim_matrix_joint_mod = torch.exp(\n",
    "            torch.mm(out_joint_mod, out_joint_mod.t().contiguous()) / temperature\n",
    "        )\n",
    "        # Mask for remove diagonal that give trivial similarity, [2*B, 2*B]\n",
    "        mask_joint_mod = (\n",
    "            torch.ones_like(sim_matrix_joint_mod)\n",
    "            - torch.eye(2 * batch_size, device=sim_matrix_joint_mod.device)\n",
    "        ).bool()\n",
    "        # Remove 2*B diagonals and reshape to [2*B, 2*B-1]\n",
    "        sim_matrix_joint_mod = sim_matrix_joint_mod.masked_select(\n",
    "            mask_joint_mod\n",
    "        ).view(2 * batch_size, -1)\n",
    "\n",
    "        # Positive pairs: cosine loss joint-modality\n",
    "        pos_sim_joint_mod = torch.exp(\n",
    "            torch.sum(\n",
    "                batch_representations[-1] * batch_representations[mod], dim=-1\n",
    "            )\n",
    "            / temperature\n",
    "        )\n",
    "        # [2*B]\n",
    "        pos_sim_joint_mod = torch.cat([pos_sim_joint_mod, pos_sim_joint_mod], dim=0)\n",
    "        loss_joint_mod = -torch.log(\n",
    "            pos_sim_joint_mod / sim_matrix_joint_mod.sum(dim=-1)\n",
    "        )\n",
    "        joint_mod_loss_sum += loss_joint_mod\n",
    "        \n",
    "        # print(torch.mean(loss_joint_mod).item())\n",
    "\n",
    "    supervised_loss =  criterion(prediction[-1], target)\n",
    "    joint_mod_loss_sum *= cl_rate\n",
    "    \n",
    "    L_GCM = torch.mean(joint_mod_loss_sum).item()\n",
    "    L_classify = torch.mean(supervised_loss).item()\n",
    "    # print(L_GCM)\n",
    "    # print(L_classify)\n",
    "    \n",
    "\n",
    "    loss = torch.mean(joint_mod_loss_sum + supervised_loss)\n",
    "    # loss = torch.mean(supervised_loss)\n",
    "    \n",
    "    return loss,L_GCM,L_classify\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, device, T, loss_log):\n",
    "    running_loss = 0\n",
    "    loss_gcm = 0\n",
    "    loss_classify = 0\n",
    "    model.train()\n",
    "\n",
    "    for videos, labels, emgs in tqdm(train_loader):\n",
    "\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "        emgs = emgs.to(device).double()\n",
    "       \n",
    "        # forward\n",
    "        outputs, outputs2 = model(videos, emgs)\n",
    "            \n",
    "        # backward\n",
    "        loss,L_GMC,classification_loss = super_gmc_loss(criterion,outputs2,labels,outputs,run.config['T'],len(labels), run.config['cl_rate'])\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        loss_gcm += L_GMC\n",
    "        loss_classify += classification_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = running_loss / (len(train_loader))\n",
    "    loss_gcm = loss_gcm / (len(train_loader))\n",
    "    loss_classify = loss_classify / (len(train_loader))\n",
    "    loss_log[0].append(loss_gcm)\n",
    "    loss_log[1].append(loss_classify)\n",
    "    loss_log[2].append(epoch_loss)\n",
    "\n",
    "    return model, epoch_loss, optimizer, loss_log\n",
    "\n",
    "\n",
    "def validate(valid_loader, model, criterion, device, T, val_loss_log):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    loss_gcm = 0\n",
    "    loss_classify = 0\n",
    "\n",
    "    for videos, labels, emgs in tqdm(valid_loader):\n",
    "\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "        emgs = emgs.to(device).double()\n",
    "        L_GMC = 0\n",
    "        # forward\n",
    "        outputs, outputs2 = model(videos, emgs)\n",
    "\n",
    "        loss,L_GMC,classification_loss = super_gmc_loss(criterion,outputs2,labels,outputs,run.config['T'],len(labels),run.config['cl_rate'])\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        loss_gcm += L_GMC\n",
    "        loss_classify += classification_loss\n",
    "\n",
    "    epoch_loss = running_loss / (len(valid_loader))\n",
    "    loss_gcm = loss_gcm / (len(valid_loader))\n",
    "    loss_classify = loss_classify / (len(valid_loader))\n",
    "    val_loss_log[0].append(loss_gcm)\n",
    "    val_loss_log[1].append(loss_classify)\n",
    "    val_loss_log[2].append(epoch_loss)\n",
    "    return model, epoch_loss, val_loss_log\n",
    "\n",
    "\n",
    "def get_accuracy(model, data_loader, device, modality='multimodal'):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    truth_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    for videos, labels, emgs in data_loader:\n",
    "        videos = videos.to(device)\n",
    "        labels = labels.to(device)\n",
    "        emgs = emgs.to(device).double()\n",
    "\n",
    "        # forward\n",
    "        _, outputs = model(videos, emgs)\n",
    "        if modality == 'multimodal':\n",
    "            predicted = torch.argmax(torch.softmax(outputs[-1], 1), 1)\n",
    "        elif modality == 'emg':\n",
    "            \n",
    "            predicted = torch.argmax(torch.softmax(outputs[1], 1), 1)\n",
    "        else:\n",
    "            predicted = torch.argmax(torch.softmax(outputs[0], 1), 1)\n",
    "\n",
    "        total += labels.shape[0]\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        predicted_labels.extend(predicted)\n",
    "        truth_labels.extend(labels)\n",
    "\n",
    "    f1_micro = f1_score(torch.tensor(truth_labels).cpu().data.numpy(\n",
    "    ), torch.tensor(predicted_labels).cpu().data.numpy(), average='macro')\n",
    "    precision_score_f1 = precision_score(torch.tensor(truth_labels).cpu().data.numpy(\n",
    "    ), torch.tensor(predicted_labels).cpu().data.numpy(), average='macro')\n",
    "    recall_score_f1 = recall_score(torch.tensor(truth_labels).cpu().data.numpy(\n",
    "    ), torch.tensor(predicted_labels).cpu().data.numpy(), average='macro')\n",
    "\n",
    "    return correct/total, f1_micro, precision_score_f1, recall_score_f1,predicted_labels,truth_labels\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(run.config[\"random_seed\"])\n",
    "\n",
    "trainset = MultiModalData(\"data/new_data/new_train_files.pkl\")\n",
    "testset = MultiModalData(\"data/new_data/new_test_files.pkl\")\n",
    "valset = MultiModalData(\"data/new_data/new_val_files.pkl\")\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=run.config['batch_size'],\n",
    "                          drop_last=False, num_workers=3, shuffle=True)\n",
    "valid_loader = DataLoader(valset, batch_size=run.config['batch_size'],\n",
    "                          drop_last=False, num_workers=3 )\n",
    "test_loader = DataLoader(testset, batch_size=run.config['batch_size'],\n",
    "                         drop_last=False, num_workers=3)\n",
    "\n",
    "\n",
    "device = run.config['device']\n",
    "model = MultiModal(\n",
    "    common_dim=run.config['common_dim'], n_classes=run.config['n_classes']).to(device)\n",
    "model.load_state_dict(torch.load(\"log/Missing_modal2/best_model59.pth\"))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "val_acc, f1_score_micro, precision_score_micro, recall_score_micro,predicted_labels,truth_labels = get_accuracy(\n",
    "        model, test_loader, device,'vid')\n",
    "print(val_acc, f1_score_micro, precision_score_micro, recall_score_micro)\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from loader.dataloader import SpectrogramData\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10464\n"
     ]
    }
   ],
   "source": [
    "data = SpectrogramData(\"data/new_data/emg_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " tensor(40),\n",
       " tensor([[[-6.8987e-05+0.0000e+00j, -7.8284e-05+0.0000e+00j,\n",
       "           -3.1138e-05+0.0000e+00j,  ...,\n",
       "            1.2430e-04+0.0000e+00j, -9.0423e-05+0.0000e+00j,\n",
       "           -7.7840e-05+0.0000e+00j],\n",
       "          [ 4.7402e-05-3.8123e-05j,  2.7431e-05-1.1573e-05j,\n",
       "           -5.3318e-06+5.9286e-05j,  ...,\n",
       "           -4.3801e-04-4.0099e-04j, -5.9275e-05+2.5222e-04j,\n",
       "            1.0619e-04+4.1414e-05j],\n",
       "          [-1.6749e-05+4.1634e-05j,  7.0033e-06+7.8769e-06j,\n",
       "            5.7369e-06-8.2540e-05j,  ...,\n",
       "            5.0735e-04+8.0431e-04j,  3.5974e-05-1.3661e-04j,\n",
       "           -3.3681e-05-1.4023e-04j],\n",
       "          ...,\n",
       "          [ 4.0287e-07+3.6197e-08j, -5.2112e-07+1.4716e-07j,\n",
       "           -5.6393e-07-1.3571e-07j,  ...,\n",
       "            3.9347e-07+6.7824e-07j,  8.8343e-07+4.6096e-07j,\n",
       "           -1.5179e-06+4.4456e-07j],\n",
       "          [-4.1944e-07+0.0000e+00j,  3.1974e-07+0.0000e+00j,\n",
       "            2.5572e-07+0.0000e+00j,  ...,\n",
       "           -4.9628e-07+0.0000e+00j, -1.3422e-06+0.0000e+00j,\n",
       "            1.3934e-06+0.0000e+00j],\n",
       "          [ 0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j,  ...,\n",
       "            0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j]],\n",
       " \n",
       "         [[-2.3860e-05+0.0000e+00j,  4.3131e-04+0.0000e+00j,\n",
       "           -3.9204e-04+0.0000e+00j,  ...,\n",
       "           -5.0719e-04+0.0000e+00j,  7.4490e-04+0.0000e+00j,\n",
       "            1.4035e-04+0.0000e+00j],\n",
       "          [ 1.0732e-04+5.5752e-05j, -3.8256e-04-3.5914e-05j,\n",
       "            1.7909e-04+1.9786e-05j,  ...,\n",
       "            2.5613e-04-3.1606e-04j, -6.7034e-04+6.2997e-04j,\n",
       "            1.4283e-04-1.7215e-04j],\n",
       "          [-1.5524e-04+4.1154e-05j,  1.4216e-04-1.5398e-04j,\n",
       "            4.2883e-05-2.4992e-04j,  ...,\n",
       "            9.8002e-05+3.3152e-04j,  2.5086e-04-3.8692e-04j,\n",
       "           -2.1731e-04-1.5671e-04j],\n",
       "          ...,\n",
       "          [ 3.1397e-06-1.8783e-07j, -2.8517e-07-1.1033e-07j,\n",
       "            6.1469e-07-8.9526e-08j,  ...,\n",
       "           -4.9915e-07+2.5091e-07j,  7.6679e-08-3.2321e-07j,\n",
       "           -4.7432e-06+1.5225e-06j],\n",
       "          [-3.1128e-06+0.0000e+00j,  3.3057e-07+0.0000e+00j,\n",
       "           -7.4785e-07+0.0000e+00j,  ...,\n",
       "            4.2217e-07+0.0000e+00j,  1.2605e-07+0.0000e+00j,\n",
       "            4.9867e-06+0.0000e+00j],\n",
       "          [ 0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j,  ...,\n",
       "            0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j]],\n",
       " \n",
       "         [[ 8.3028e-04+0.0000e+00j,  1.1805e-03+0.0000e+00j,\n",
       "           -2.1305e-04+0.0000e+00j,  ...,\n",
       "           -5.7655e-04+0.0000e+00j, -2.0502e-04+0.0000e+00j,\n",
       "           -7.9907e-04+0.0000e+00j],\n",
       "          [-2.7513e-04+7.2173e-04j, -6.5561e-04-6.1718e-04j,\n",
       "            5.1420e-04+2.2707e-04j,  ...,\n",
       "            2.6120e-04+2.4470e-04j, -4.6800e-04-3.6774e-04j,\n",
       "            2.3514e-04+7.0933e-04j],\n",
       "          [-4.1599e-04-4.6302e-04j,  3.1920e-04+1.8313e-04j,\n",
       "           -7.1233e-04+2.5793e-04j,  ...,\n",
       "            2.2751e-04-3.5453e-04j,  9.5813e-04-1.1449e-04j,\n",
       "            4.7893e-04-3.4643e-04j],\n",
       "          ...,\n",
       "          [ 3.7921e-06+3.2310e-08j, -5.4475e-07-7.5595e-07j,\n",
       "           -6.3778e-08-8.5643e-07j,  ...,\n",
       "           -1.9428e-06+1.0924e-08j,  1.4418e-07+5.6444e-07j,\n",
       "            1.8751e-06-6.8645e-07j],\n",
       "          [-3.9463e-06+0.0000e+00j,  6.9030e-07+0.0000e+00j,\n",
       "            8.1907e-07+0.0000e+00j,  ...,\n",
       "            2.1233e-06+0.0000e+00j,  1.1268e-07+0.0000e+00j,\n",
       "           -1.9387e-06+0.0000e+00j],\n",
       "          [ 0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j,  ...,\n",
       "            0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 6.2326e-05+0.0000e+00j,  7.3231e-04+0.0000e+00j,\n",
       "           -4.6293e-04+0.0000e+00j,  ...,\n",
       "           -1.2388e-03+0.0000e+00j,  6.7844e-04+0.0000e+00j,\n",
       "           -4.4587e-04+0.0000e+00j],\n",
       "          [ 1.4459e-04+2.3774e-04j, -5.5473e-04-2.5510e-04j,\n",
       "            1.1472e-03+3.8846e-04j,  ...,\n",
       "            8.3003e-04+4.1486e-04j, -1.1843e-03-8.7063e-04j,\n",
       "           -2.7325e-05+4.8518e-04j],\n",
       "          [-4.0655e-04-1.2106e-04j,  4.2626e-04+7.7991e-05j,\n",
       "           -1.2799e-03+6.1057e-04j,  ...,\n",
       "            1.4461e-04-3.5528e-04j,  1.3351e-03+1.0301e-03j,\n",
       "            4.9718e-04-8.6468e-05j],\n",
       "          ...,\n",
       "          [ 1.0109e-05-2.3728e-07j,  7.0090e-07-2.8311e-07j,\n",
       "           -4.8336e-07-8.9595e-07j,  ...,\n",
       "            2.8408e-07+8.3744e-07j, -1.4118e-06-7.6857e-07j,\n",
       "            1.2264e-05-3.6326e-06j],\n",
       "          [-1.0131e-05+0.0000e+00j, -2.4420e-07+0.0000e+00j,\n",
       "            1.7682e-06+0.0000e+00j,  ...,\n",
       "            9.1089e-08+0.0000e+00j,  9.6041e-07+0.0000e+00j,\n",
       "           -1.2614e-05+0.0000e+00j],\n",
       "          [ 0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j,  ...,\n",
       "            0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j]],\n",
       " \n",
       "         [[ 2.3937e-03+0.0000e+00j, -6.6195e-04+0.0000e+00j,\n",
       "           -6.6019e-04+0.0000e+00j,  ...,\n",
       "           -6.1961e-04+0.0000e+00j, -2.8785e-04+0.0000e+00j,\n",
       "           -8.8531e-04+0.0000e+00j],\n",
       "          [-7.4056e-04+1.9696e-03j,  1.3409e-03-3.9001e-03j,\n",
       "           -7.0637e-07+6.8744e-04j,  ...,\n",
       "            2.3304e-04+6.8938e-05j, -5.1603e-04-3.5202e-04j,\n",
       "            2.7316e-04+7.6954e-04j],\n",
       "          [-9.4559e-04-1.0358e-03j, -9.7480e-04+3.2402e-03j,\n",
       "           -1.5475e-04+8.6942e-04j,  ...,\n",
       "            3.0522e-04-1.7258e-04j,  1.0930e-03-8.8748e-05j,\n",
       "            4.8824e-04-3.7739e-04j],\n",
       "          ...,\n",
       "          [ 7.2950e-06-7.6217e-07j,  2.4931e-07-7.8927e-07j,\n",
       "           -1.9453e-06-3.2419e-07j,  ...,\n",
       "           -3.1764e-06+9.9876e-07j, -5.7627e-07+3.5960e-07j,\n",
       "           -2.0864e-07-6.2628e-07j],\n",
       "          [-7.2286e-06+0.0000e+00j, -4.4389e-07+0.0000e+00j,\n",
       "            1.8378e-06+0.0000e+00j,  ...,\n",
       "            4.7433e-06+0.0000e+00j,  3.9285e-07+0.0000e+00j,\n",
       "           -3.6111e-07+0.0000e+00j],\n",
       "          [ 0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j,  ...,\n",
       "            0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j]],\n",
       " \n",
       "         [[ 2.0205e-03+0.0000e+00j,  3.4965e-04+0.0000e+00j,\n",
       "           -8.7128e-04+0.0000e+00j,  ...,\n",
       "           -4.2614e-04+0.0000e+00j, -1.0936e-04+0.0000e+00j,\n",
       "           -8.4167e-04+0.0000e+00j],\n",
       "          [-6.4118e-04+1.6331e-03j,  4.8205e-04-2.9756e-03j,\n",
       "            2.9632e-04-3.3112e-04j,  ...,\n",
       "            1.9874e-04+1.3028e-04j, -5.1793e-04-6.0159e-04j,\n",
       "            2.5712e-04+7.2149e-04j],\n",
       "          [-7.2933e-04-8.6471e-04j, -4.4646e-04+2.6004e-03j,\n",
       "           -1.8509e-04+1.6222e-03j,  ...,\n",
       "            2.4744e-04-3.5055e-05j,  8.7026e-04+2.0492e-04j,\n",
       "            4.3262e-04-3.4887e-04j],\n",
       "          ...,\n",
       "          [ 5.1418e-06+4.8708e-07j, -3.3319e-07-2.9386e-07j,\n",
       "           -1.4677e-06-1.6637e-06j,  ...,\n",
       "           -1.8993e-06+9.1648e-08j, -4.8960e-07+6.8464e-08j,\n",
       "            4.7139e-07-8.5685e-08j],\n",
       "          [-5.5161e-06+0.0000e+00j, -3.4046e-07+0.0000e+00j,\n",
       "            2.0120e-06+0.0000e+00j,  ...,\n",
       "            2.5028e-06+0.0000e+00j,  1.4142e-06+0.0000e+00j,\n",
       "           -1.7119e-07+0.0000e+00j],\n",
       "          [ 0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j,  ...,\n",
       "            0.0000e+00+0.0000e+00j,  0.0000e+00+0.0000e+00j,\n",
       "            0.0000e+00+0.0000e+00j]]], dtype=torch.complex128))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import ViT\n",
    "from VITforEMGAndBone import ViTForEMGAndBone, CrossAttention\n",
    "from GCNforVIdeo import GGCN, find_adjacency_matrix\n",
    "from torch import nn\n",
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "import math\n",
    "from loader.dataloader import MultiModalData\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from util.log import Log\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import wandb\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttentionFor3Modalites(nn.Module):\n",
    "    def __init__(self,dim1,dim2,out_dim):\n",
    "        super(CrossAttentionFor3Modalites, self).__init__()\n",
    "        self.crossAtt1 = CrossAttention(dim1, dim2, out_dim).double()\n",
    "        self.crossAtt2 = CrossAttention(dim2, dim1, out_dim).double()\n",
    "        \n",
    "    def forward(self,modality1,modality2):\n",
    "        x1 =  self.crossAtt1(modality1,modality2)\n",
    "        x2 =  self.crossAtt2(modality2,modality1)\n",
    "        return torch.concat([x1,x2],dim = -1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5, 14560])\n"
     ]
    }
   ],
   "source": [
    "modality1 = torch.rand((5,5,21,3))\n",
    "modality2 = torch.rand((5,8820,8))\n",
    "modality3 = torch.rand((5,8,130,70))\n",
    "modality1 = rearrange(modality1,\"a b c d-> a b (c d)\").double()\n",
    "modality2 = rearrange(modality2, \"b (a d) c ->b a (d c) \", a=5).double()\n",
    "modality3 = rearrange(rearrange(modality3, \"b c a d ->b d (c a)\"),\"b (a e) f-> b a (e f)\",a = 5).double()\n",
    "# modality3 = nn.Linear(modality3.shape[-1],1024)(modality3)\n",
    "\n",
    "\n",
    "# md1 = CrossAttentionFor3Modalites(63,14112,256).double()\n",
    "# md2 = CrossAttentionFor3Modalites(63,72800,256).double()\n",
    "# md3 = CrossAttentionFor3Modalites(72800,14112,256).double()\n",
    "\n",
    "# print(md1(modality1,modality2).shape,md2(modality1,modality3).shape,md3(modality3,modality2).shape)\n",
    "print(modality3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/new_data/new_spectrogram/PhongTrang_20230701_02_P_12.pkl\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "data = glob.glob(\"data/new_data/new_spectrogram/*\")\n",
    "for url in data:\n",
    "    spectrogram, label = torch.load(url.replace(\"emg_data\",\"spectrogram\"))\n",
    "    if spectrogram.shape[1]> 130:\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anhnct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
